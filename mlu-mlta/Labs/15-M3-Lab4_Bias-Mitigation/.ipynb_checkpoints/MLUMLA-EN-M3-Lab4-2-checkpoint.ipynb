{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../common/images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"600\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# ML through Application \n",
    "## Module 3, Lab 4, Notebook 2: Bias Mitigation during Training\n",
    "\n",
    "This notebook shows how to implement a fairness criteria with the goal to train a model that produces a more fair outcome compared to a model that is trained without bias mitigation.\n",
    "\n",
    "You will learn how to do the following:\n",
    "- Build a simple classifier by using a scikit-learn pipeline and ColumnTransformer.\n",
    "- Implement a bias mitigation step by using reweighing (manually and using a fairness Python library).\n",
    "- Compare bias in data before training and bias in the model predictions.\n",
    "\n",
    "__Dataset:__ \n",
    "You will use [Folktables](https://github.com/zykls/folktables) to download a dataset for this lab. Folktables provides an API to download data from the American Community Survey (ACS) Public Use Microdata Sample (PUMS) files, which the U.S. Census Bureau manages. The data itself is governed by the terms of use that are provided by the Census Bureau. For more information, see the [Terms of Service](https://www.census.gov/data/developers/about/terms-of-service.html). \n",
    "\n",
    "You will filter the ACS PUMS data sample to include only individuals who are above the age of 16, reported usual working hours of at least 1 hour per week in the past year, and have an income of at least \\\\$100. \n",
    "The threshold of \\\\$50,000 was chosen so that this dataset can serve as a comparable replacement to the [UCI Adult dataset](https://archive.ics.uci.edu/ml/datasets/adult), but the income threshold can be changed easily to define new prediction tasks. Historically, the [UCI Adult dataset](https://archive.ics.uci.edu/ml/datasets/adult) served as the basis for the development and comparison of many algorithmic fairness interventions but has limited documentation, outdated feature encodings, and only contains a binary target label which can lead to misrepresentations for certain subpopulations. In order to compare your results with scientific findings that utilize the UCI Adult dataset, and to have greater control and flexibility in setting up the problem, you will utilize the ACS PUMS data with the filters and thresholds described above.\n",
    "\n",
    "__ML problem:__ \n",
    "The goal is to predict whether an individual's income is above \\\\$50,000. \n",
    "This is a binary prediction task that can enable organizations and businesses to target their marketing efforts more effectively. Alternatively, governments could leverage these predictions to design better social welfare programs and allocate resources efficiently. Keep these kinds of problems in mind, when working through the notebook.\n",
    "\n",
    "Reference: Dua, D. and Graff, C. (2019). UCI Machine Learning Repository. http://archive.ics.uci.edu/ml. Irvine, CA: University of California, School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- [Read in the dataset](#Read-in-the-dataset)\n",
    "- [Data processing](#Data-processing)\n",
    "- [Train a classifier](#Train-a-classifier)\n",
    "- [Test the classifier](#Test-the-classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading in the dataset, make sure to install and import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Use pip to install libraries\n",
    "!pip install --no-deps -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Import the libraries needed for the notebook\n",
    "\n",
    "# Reshaping/basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "# Import questions\n",
    "from MLUMLA_EN_M3_Lab4_quiz_questions import *\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fairness libraries\n",
    "from folktables.acs import *\n",
    "from folktables.folktables import *\n",
    "from folktables.load_acs import *\n",
    "\n",
    "# Jupyter(lab) libraries\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Read in the dataset\n",
    "\n",
    "Import the data from Folktables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "income_features = [\n",
    "    \"AGEP\",  # age individual\n",
    "    \"COW\",  # class of worker\n",
    "    \"SCHL\",  # educational attainment\n",
    "    \"MAR\",  # marital status\n",
    "    \"OCCP\",  # occupation\n",
    "    \"POBP\",  # place of birth\n",
    "    \"RELP\",  # relationship\n",
    "    \"WKHP\",  # hours worked per week past 12 months\n",
    "    \"SEX\",  # sex\n",
    "    \"RAC1P\",  # recorded detailed race code\n",
    "    \"PWGTP\",  # persons weight\n",
    "    \"GCL\",  # grandparents living with grandchildren\n",
    "]\n",
    "\n",
    "# Define the prediction problem and features\n",
    "ACSIncome = folktables.BasicProblem(\n",
    "    features=income_features,\n",
    "    target=\"PINCP\",  # total persons income\n",
    "    target_transform=lambda x: x > 50000,\n",
    "    group=\"RAC1P\",\n",
    "    preprocess=adult_filter,  # applies the following conditions; ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "    postprocess=lambda x: x,  # applies post processing, for example: fill all NAs\n",
    ")\n",
    "\n",
    "# Initialize year, duration (\"1-Year\" or \"5-Year\") and granularity (household or person)\n",
    "data_source = ACSDataSource(survey_year=\"2018\", horizon=\"1-Year\", survey=\"person\")\n",
    "# Specify region (here: California) and load data\n",
    "ca_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "# Apply transformation as per problem statement above\n",
    "ca_features, ca_labels, ca_group = ACSIncome.df_to_numpy(ca_data)\n",
    "\n",
    "# Convert NumPy array to DataFrame\n",
    "df = pd.DataFrame(\n",
    "    np.concatenate((ca_features, ca_labels.reshape(-1, 1)), axis=1),\n",
    "    columns=income_features + [\">50k\"],\n",
    ")\n",
    "\n",
    "# For further modeling, use only two groups\n",
    "df = df[df[\"RAC1P\"].isin([6, 8])].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data processing\n",
    "\n",
    "Next, split the categorical and numerical features to keep them separate. Start by creating a list for each feature type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"COW\",\n",
    "    \"SCHL\",\n",
    "    \"MAR\",\n",
    "    \"OCCP\",\n",
    "    \"POBP\",\n",
    "    \"RELP\",\n",
    "    \"SEX\",\n",
    "    \"RAC1P\",\n",
    "]\n",
    "\n",
    "numerical_features = [\"AGEP\", \"WKHP\", \"PWGTP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cast categorical features to `category`\n",
    "df[categorical_features] = df[categorical_features].astype(\"object\")\n",
    "\n",
    "# Cast numerical features to `int`\n",
    "df[numerical_features] = df[numerical_features].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now separate model features from the model target to explore them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_target = \">50k\"\n",
    "model_features = categorical_features + numerical_features\n",
    "\n",
    "print(\"Model features: \", model_features)\n",
    "print(\"Model target: \", model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check that the target is not accidentally part of the features\n",
    "model_target in model_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good. You made sure that the target is not in the feature list. If the output of the previous cell is `True`, you need to remove the target by calling `model_features.remove(model_target)`.\n",
    "\n",
    "Next, you will look for missing values.\n",
    "\n",
    "### Check for missing values\n",
    "The quickest way to check for missing values is to use `.isna().sum()`. This will provide a count of missing values.\n",
    "\n",
    "You can also see the count of missing values with `.info()` because the function provides a count of non-null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement a threshold-based way to drop columns. You want to drop all columns where more than 20 percent of the data is missing. (Note that this is an example threshold that doesn't apply universally.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.loc[:, df.isnull().mean() < 0.2]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformation\n",
    "\n",
    "Now that you dropped the missing values, implement reweighing of the features before they are passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reweighing(data, label, sensitive_attr, return_list=True):\n",
    "    \"Function that calculates reweighting factors based on given model target and sensitive attribute.\" \"\"\n",
    "    # Initialize dict for the different classes of labels\n",
    "    label_dict = dict()\n",
    "    try:\n",
    "        # Loop through different labels\n",
    "        for outcome in data[label].unique():\n",
    "            # Initialize empty dict to store weight values\n",
    "            weight_map = dict()\n",
    "            # Loop through different sensitive attributes\n",
    "            for val in data[sensitive_attr].unique():\n",
    "                # Count per outcome type, per sensitive attribute class\n",
    "                nom = (\n",
    "                    len(data[data[sensitive_attr] == val])\n",
    "                    / len(data)\n",
    "                    * len(data[data[label] == outcome])\n",
    "                    / len(data)\n",
    "                )\n",
    "                denom = len(\n",
    "                    data[(data[sensitive_attr] == val) & (data[label] == outcome)]\n",
    "                ) / len(data)\n",
    "                # Calculate fraction to obtain weight\n",
    "                weight_map[val] = round(nom / denom, 2)\n",
    "            # Store output in list\n",
    "            label_dict[outcome] = weight_map\n",
    "        # Map values back to correct data points\n",
    "        data[\"weights\"] = list(\n",
    "            map(lambda x, y: label_dict[y][x], data[sensitive_attr], data[label])\n",
    "        )\n",
    "        # Enable to return a list of the weights\n",
    "        if return_list == True:\n",
    "            return data[\"weights\"].to_list()\n",
    "        else:\n",
    "            return label_dict\n",
    "    # Catch error\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print(\"Dataframe might have no entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use a custom function to calculate reweighting\n",
    "weights = pd.DataFrame({\"weights\": reweighing(df, model_target, \"RAC1P\", True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features to build the model \n",
    "\n",
    "The GCL feature is equally present in both outcome instances and also contains a lot of missing values. Therefore, you can drop it from the list of features that you want to use for model build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_remove = \"GCL\"\n",
    "\n",
    "# Drop GCL feature from the respective list(s) - if applicable\n",
    "if to_remove in model_features:\n",
    "    model_features.remove(to_remove)\n",
    "if to_remove in categorical_features:\n",
    "    categorical_features.remove(to_remove)\n",
    "if to_remove in numerical_features:\n",
    "    numerical_features.remove(to_remove)\n",
    "\n",
    "# Clean up the DataFrame and only keep the features and columns that are needed\n",
    "df = df[model_features + [model_target]].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training, test, and validation datasets \n",
    "\n",
    "To get training, test, and validation sets, use scikit-learn's [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    df, test_size=0.1, shuffle=True, random_state=23\n",
    ")\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    train_data, test_size=0.15, shuffle=True, random_state=23\n",
    ")\n",
    "\n",
    "# Print the shapes of the Train - Test Datasets\n",
    "print(\n",
    "    \"Train - Test - Validation dataset shapes: \",\n",
    "    train_data.shape,\n",
    "    test_data.shape,\n",
    "    val_data.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the sensitive feature before the data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_features.remove(\"RAC1P\")\n",
    "model_features.remove(\"RAC1P\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the data with a pipeline and ColumnTransformer \n",
    "\n",
    "Now you can build a full model pipeline. You need a preprocessing split per data type. Then, you will combine everything into a composite pipeline along with a model. To achieve this, you will use scikit-learn's `Pipeline` and `ColumnTransformer`.\n",
    "\n",
    "__Step 1: Set up preprocessing per data type__\n",
    "\n",
    "For the numerical features pipeline (`numerical_processor` in the following code cell), impute missing values with the mean by using scikit-learn's `SimpleImputer`. Then, use `MinMaxScaler` (you don't need to scale features when using decision trees, but it's a good idea to see how to use data transforms). If different processing is desired for different numerical features, you should build different pipelines, as shown for the two categorical text features.\n",
    "\n",
    "In the categorical features pipeline, (`categorical_processor` in the following code cell), impute with a placeholder value and encode with scikit-learn's `OneHotEncoder`. If computing memory is an issue, it is a good idea to check unique values for categoricals to get an estimate of how many dummy features will be created by one-hot encoding. Note the `handle_unknown` parameter, which tells the encoder to ignore (rather than throw an error for) any unique value that might show in the validation or test set that was not present in the initial training set.\n",
    " \n",
    "__Step 2: Combine preprocessing methods into a transformer__ \n",
    "\n",
    "The selective preparations of the dataset features are then put together into a collective `ColumnTransformer` to finally be used in a pipeline along with an estimator. This ensures that the transforms are performed automatically on the raw data when fitting the model and when making predictions, such as when evaluating the model on a validation dataset through cross-validation or making predictions on a test dataset in the future.\n",
    "   \n",
    "__Step 3: Combine the transformer with a model__ \n",
    "\n",
    "Combine `ColumnTransformer` from step 2 with a selected algorithm in a new pipeline. For example, the algorithm could be a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### STEP 1 ###\n",
    "##############\n",
    "\n",
    "# Preprocess the numerical features\n",
    "numerical_processor = Pipeline(\n",
    "    [(\"num_imputer\", SimpleImputer(strategy=\"mean\")), (\"num_scaler\", MinMaxScaler())]\n",
    ")\n",
    "# Preprocess the categorical features\n",
    "categorical_processor = Pipeline(\n",
    "    [\n",
    "        (\"cat_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "### STEP 2 ###\n",
    "##############\n",
    "\n",
    "# Combine all data preprocessors from step 1\n",
    "data_processor = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical_processing\", numerical_processor, numerical_features),\n",
    "        (\"categorical_processing\", categorical_processor, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "### STEP 3 ###\n",
    "##############\n",
    "\n",
    "# Pipeline desired all data transformers, along with an estimator at the end\n",
    "# Later you can set or reach the parameters by using the names issued - for hyperparameter tuning, for example\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"data_processing\", data_processor),\n",
    "        (\"lg\", LogisticRegression(solver=\"liblinear\", penalty=\"l2\", C=0.001)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualize the pipeline\n",
    "# This will be helpful, especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train a classifier\n",
    "\n",
    "To train a classifier, you will use the pipeline with the desired data transformers, along with a logistic regression estimator for training.\n",
    "\n",
    "Train the classifier with `.fit()` on the training dataset. In the fit method, you will pass the sample weights. The parameter name will depend on the naming choices of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get training data to train the classifier\n",
    "X_train = train_data[model_features]\n",
    "y_train = train_data[model_target]\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "# Training data going through the pipeline is imputed (with means from the training data),\n",
    "#   scaled (with the min/max from the training data),\n",
    "#   and finally used to fit the model\n",
    "pipeline.fit(\n",
    "    X_train, y_train, lg__sample_weight=weights.loc[train_data.index].values.ravel()\n",
    ")\n",
    "\n",
    "y_train_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get validation data to tune the classifier\n",
    "X_val = val_data[model_features]\n",
    "y_val = val_data[model_target]\n",
    "\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "print(\"Model performance on the validation set:\")\n",
    "print(\"Validation accuracy:\", accuracy_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Test the classifier \n",
    "\n",
    "Now, evaluate the performance of the trained classifier on the test dataset by using `.predict()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get test data to validate the classifier\n",
    "X_test = test_data[model_features]\n",
    "y_test = test_data[model_target]\n",
    "\n",
    "# Use the fitted model to make predictions on the test dataset\n",
    "# Test data going through the pipeline is imputed (with means from the training data),\n",
    "#   scaled (with the min/max from the training data),\n",
    "#   and finally used to make predictions\n",
    "test_predictions = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Model performance on the test set:\")\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model again, but this time, don't use the weights. This will be helpful for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "test_predictions_no_weights = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame that contains predictions and the sensitive attribute\n",
    "output_df = pd.concat(\n",
    "    [\n",
    "        test_data.reset_index(drop=True)[[\"RAC1P\", \">50k\"]],\n",
    "        pd.Series(test_predictions, name=\"y_test_pred_weighted\"),\n",
    "        pd.Series(test_predictions_no_weights, name=\"y_test_pred_noweights\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    x=\"RAC1P\",\n",
    "    kind=\"count\",\n",
    "    hue=model_target,\n",
    "    data=output_df,\n",
    "    palette=\"husl\",\n",
    "    sharey=True,\n",
    ")\n",
    "plt.ylim(0, 2900)\n",
    "sns.catplot(\n",
    "    x=\"RAC1P\",\n",
    "    kind=\"count\",\n",
    "    hue=\"y_test_pred_weighted\",\n",
    "    data=output_df,\n",
    "    palette=\"husl\",\n",
    "    sharey=True,\n",
    ")\n",
    "plt.ylim(0, 2900)\n",
    "sns.catplot(\n",
    "    x=\"RAC1P\",\n",
    "    kind=\"count\",\n",
    "    hue=\"y_test_pred_noweights\",\n",
    "    data=output_df,\n",
    "    palette=\"husl\",\n",
    "    sharey=True,\n",
    ")\n",
    "plt.ylim(0, 2900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "Using weights during model training has an impact on the predictions. A large number of people in group 6 that would have been predicted as outcome 1 (for a model without weights), now receive outcome 0. Group 8 also has more individuals with a positive outcome (when using weights).\n",
    "\n",
    "This is more fair between the groups, but is this fair for individuals who now have a negative (0) outcome? It's important to think about what it means to have more people who are predicted 0 in group 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To finish this lab, continue to notebook 3.**"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
