{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffb6761",
   "metadata": {},
   "source": [
    "<center><img src=\"../common/images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"600\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "# Application of Deep Learning to Text and Image Data\n",
    "## Module 3, Lab 6: Fine-Tuning ConvNeXt\n",
    "\n",
    "This notebook will show you how to import a pretrained ConvNeXt model and fine-tune it to solve a classification problem. You will train this model with a dataset and then test and visualize the results.\n",
    "\n",
    "You will learn how to do the following:\n",
    "\n",
    "- Load and transform the ConvNeXt dataset\n",
    "- Fine-tune the model to fit your data\n",
    "- Test, evaluate, and visualize the results\n",
    "\n",
    "----\n",
    "\n",
    "You will be presented with a challenge at the end of this lab:\n",
    "\n",
    "| <img style=\"float: center;\" src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"125\"/> |\n",
    "| --- |\n",
    "| <p style=\"text-align:center;\">Challenges are where you can practice your coding skills.</p> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b484f-c673-41ca-9759-7f1b421f002c",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- [Loading and transforming the dataset](#Loading-and-transforming-the-dataset)\n",
    "- [Fine-tuning the model](#Fine-tuning-the-model)\n",
    "- [Testing and visualizations](#Testing-and-visualizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c9e56d",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading and transforming the dataset\n",
    "\n",
    "You will be fine-tuning a ConvNeXt model to work with the Materials in Context Database (MINC). To start, use the same steps as the previous lab to use transform functions and create data loaders to load the data.\n",
    "\n",
    "Reference: Sean Bell, Paul Upchurch, Noah Snavely, and Kavita Bala. \"Material Recognition in the Wild with the Materials in Context Database.\" *Computer Vision and Pattern Recognition (CVPR)*, April 2015. https://arxiv.org/abs/1412.0623."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c486bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install libraries\n",
    "!pip install -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f57720-904a-4d51-aba4-92a1ff8be232",
   "metadata": {},
   "source": [
    "Import the PyTorch packages and modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3144071-81cc-4f64-b553-72d464e50106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim import SGD\n",
    "from torchvision.models import convnext_base, convnext_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be182bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0,0,0), std=(1,1,1))\n",
    "])\n",
    "\n",
    "# Create the data loaders\n",
    "batch_size = 16\n",
    "#path = '/home/ec2-user/SageMaker/data/minc-2500'  # for MLU internal test only\n",
    "path = '../data/minc-2500'\n",
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'val')\n",
    "test_path = os.path.join(path, 'test')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    ImageFolder(train_path, transform=transform),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    ImageFolder(val_path, transform=transform),\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    ImageFolder(test_path, transform=transform),\n",
    "    batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536bed1",
   "metadata": {},
   "source": [
    "---\n",
    "## Fine-tuning the model\n",
    "\n",
    "You can start with a base model and fine-tune it to improve its performance with the dataset that you are using. This helps you to create a better model using fewer resources.\n",
    "\n",
    "You will take the following steps:\n",
    "1. Start with a ConvNeXt model that was trained with the ImageNet dataset as the base model.\n",
    "1. Import the `convnext_tiny` model with the `IMAGENET1K_V1` weights.\n",
    "1. The original ConvNeXt model was trained for 1,000 categories. Update the last layer with a dense layer that has the same number of classes for the problem that you want to solve (6, in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2800f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = 6\n",
    "\n",
    "# Use GPU resource if available; otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = convnext_tiny(weights=\"IMAGENET1K_V1\").to(device)\n",
    "\n",
    "# Print the network to find out how to access the last layer\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fae7f7",
   "metadata": {},
   "source": [
    "Read through the output from the last command. The last layer (a linear layer) is under the __classifier__ part of the network. You can access this layer by using `net.classifier[2]`.\n",
    "\n",
    "Now that you have a classifier layer to work from, you need to create a new linear layer that has the same number of inputs and has a preselected number of outputs (6 here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f24be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_ftrs = net.classifier[2].in_features\n",
    "\n",
    "# Update the classifier so that it uses the classes that are defined for your problem\n",
    "net.classifier[2] = nn.Linear(num_ftrs, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195314c4",
   "metadata": {},
   "source": [
    "Now, train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38fc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "def calculate_accuracy(output, label):\n",
    "    \"\"\"Calculate the accuracy of the trained network. \n",
    "    output: (batch_size, num_output) float32 tensor\n",
    "    label: (batch_size, ) int32 tensor \"\"\"\n",
    "\n",
    "    return (output.argmax(axis=1) == label.float()).float().mean()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net = net.to(device) # may be redundant\n",
    "\n",
    "    train_loss, val_loss, train_acc, valid_acc = 0., 0., 0., 0.\n",
    "\n",
    "    # Training loop\n",
    "    # This loop trains the neural network (weights are updated)\n",
    "    net.train() # Activate training mode\n",
    "    for data, label in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Put data and label to the correct device\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        # Make forward pass\n",
    "        output = net(data)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, label)\n",
    "        # Make backward pass (calculate gradients)\n",
    "        loss.backward()\n",
    "        # Accumulate training accuracy and loss\n",
    "        train_acc += calculate_accuracy(output, label).item()\n",
    "        train_loss += loss.item()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    # This loop tests the trained network on the validation dataset\n",
    "    # No weight updates here\n",
    "    # torch.no_grad() reduces memory usage when not training the network\n",
    "    net.eval() # Activate evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for data, label in validation_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            # Make forward pass with the trained model so far\n",
    "            output = net(data)\n",
    "            # Accumulate validation accuracy and loss\n",
    "            valid_acc += calculate_accuracy(output, label).item()\n",
    "            val_loss += criterion(output, label).item()\n",
    "\n",
    "    # Take averages\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "    val_loss /= len(validation_loader)\n",
    "    valid_acc /= len(validation_loader)\n",
    "\n",
    "    print(\"Epoch %d: train loss %.3f, train acc %.3f, val loss %.3f, val acc %.3f\" % (\n",
    "        epoch+1, train_loss, train_acc, val_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d4823",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing and visualizations\n",
    "\n",
    "Now that you have created a model, you need to validate the model's predictions.\n",
    "\n",
    "The following code cell defines the `show_images` function. It will show the sample images and the model prediction together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be86c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    \"\"\"Plot a list of images.\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        ax.imshow(img.permute(1,2,0).numpy())\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b75bb3",
   "metadata": {},
   "source": [
    "Now that you have trained a model and created a function to test predictions, you are ready to load the test dataset, make predictions, and evaluate the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda3f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_test_dataset = ImageFolder(test_path,\n",
    "                                  transform=transform)\n",
    "random_test_sample = DataLoader(random_test_dataset,\n",
    "                                batch_size=2*8, shuffle=False)\n",
    "\n",
    "net.eval() # Activate eval mode (don't use dropouts etc.)\n",
    "for data, label in random_test_sample:\n",
    "    show_images(data, 2, 8);\n",
    "    data = data.to(device)\n",
    "    pred = net(data)\n",
    "    print(pred.argmax(axis=1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d19021-ec40-4018-ac81-367ca6ce545b",
   "metadata": {},
   "source": [
    "It shows 16 sample images in the test set above. The 16 values in the tensor are the prediction results for these 16 images. \n",
    "The labels are brick(0), carpet(1), food(2), mirror(3), sky(4), and water(5).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02393a16",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\"> \n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <p style=\"text-align:center; margin:auto;\"><img src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">ConvNeXt comes in different sizes, including <code>convnext_small</code>, <code>convnext_base</code>, and <code>convnext_large</code>.</p><br>\n",
    "    <p style=\" text-align: center; margin: auto;\">Pick one of these models, and use the following code cell to retrain your model.</p><br>\n",
    "    <p style=\" text-align: center; margin: auto;\">You only need to import the new model and replace <code>convnext_tiny</code> with <code>convnext_small</code>, <code>convnext_base</code>, or <code>convnext_large</code>, and retrain the model.</p><br>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c0a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############### CODE HERE ###############\n",
    "\n",
    "from torchvision.models import convnext_small\n",
    "from torchvision.models import convnext_base\n",
    "from torchvision.models import convnext_large\n",
    "\n",
    "net = convnext_small(weights=\"IMAGENET1K_V1\").to(device)\n",
    "net = convnext_base(weights=\"IMAGENET1K_V1\").to(device)\n",
    "net = convnext_large(weights=\"IMAGENET1K_V1\").to(device)\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6870a4-ee12-4a3c-a748-89f67edbd645",
   "metadata": {},
   "source": [
    "Now you have tried a different size of the ConvNeXt model. You can also follow the same steps above in this notebook to further evaluate your new trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f197e0-7b88-44ad-9a26-a8182a645181",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab, you learned how to fine-tune the ConvNeXt model to make better predictions that fit your dataset without training your own model. This is an easy way to quickly get started making predictions at a lower cost. The biggest problem is that the model will probably not fit your dataset well, which will require you to fine-tune the model. Fine-tuning improves model accuracy so that the model will make good predictions for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893548aa-c980-4c7f-b03c-78ef0c294848",
   "metadata": {},
   "source": [
    "__Congratulations! You have finished the last lab in this course.__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
