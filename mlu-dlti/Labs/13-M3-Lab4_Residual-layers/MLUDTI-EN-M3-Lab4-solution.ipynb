{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../common/images/logo.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# Application of Deep Learning to Text and Image Data\n",
    "## Module 3, Lab 4: Using Residual Layers\n",
    "\n",
    "This notebook covers how to implement _residual layers_ and use them to make predictions. \n",
    "\n",
    "You will learn how to do the following:\n",
    "\n",
    "- Define model evaluation metrics.\n",
    "- Define training functions.\n",
    "- Design residual layers.\n",
    "- Compare the performance of residual layers.\n",
    "\n",
    "You will use the Fashion-MNIST dataset to compare the performance of different residual layers. You will plot data over a variety of depths and examine how it compares after a single epoch of training or several epochs of training.\n",
    "\n",
    "----\n",
    "\n",
    "You will be presented with two kinds of exercises throughout the notebook: activities and challenges. <br/>\n",
    "\n",
    "| <img style=\"float: center;\" src=\"../common/images/activity.png\" alt=\"Activity\" width=\"125\"/>| <img style=\"float: center;\" src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"125\"/>|\n",
    "| --- | --- |\n",
    "|<p style=\"text-align:center;\">No coding is needed for an activity. You try to understand a concept, <br/>answer questions, or run a code cell.</p> |<p style=\"text-align:center;\">Challenges are where you can practice your coding skills.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Index\n",
    "\n",
    "- [Load the Fashion-MNIST dataset](#Load-the-Fashion-MNIST-dataset)\n",
    "- [Define the model evaluation metric and training functions](#Define-the-model-evaluation-metric-and-training-functions)\n",
    "- [Design the residual layer](#Design-the-residual-layer)\n",
    "- [Compare the performance of different residual layers](#Compare-the-performance-of-different-residual-layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Load the Fashion-MNIST dataset\n",
    "\n",
    "To get started, load the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) from `torchvision`. Then, define the training, validation, and test paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install libraries\n",
    "!pip install -q -U -r requirements.txt\n",
    "!pip install d2l==0.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restart the kernel after installing the libraries, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "def restart_kernel_and_run_all_cells():\n",
    "    display(HTML(\n",
    "        '''\n",
    "            <script>\n",
    "                code_show = false;\n",
    "                var cell_idx = Jupyter.notebook.get_cell_elements().index(cell_element);\n",
    "                cell_idx++;\n",
    "                function restart(){\n",
    "                    IPython.notebook.kernel.restart();\n",
    "                    IPython.notebook.execute_cells([cell_idx])\n",
    "                }\n",
    "                restart()\n",
    "            </script>\n",
    "        '''\n",
    "    ))\n",
    "#print(\"Before you continue, wait until the kernel is ready again.\")\n",
    "restart_kernel_and_run_all_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"You are ready to go to the next cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the PyTorch packages and modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import helper libraries\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Import local d2l functions \n",
    "#import sys\n",
    "\n",
    "#if (\"../d2l-utils/model\") not in sys.path:\n",
    "#    sys.path.append(\"../d2l-utils/model\")\n",
    "\n",
    "#if (\"../d2l-utils/train\") not in sys.path:\n",
    "#    sys.path.append(\"../d2l-utils/train\")\n",
    "\n",
    "#sys.path.insert(1, '..')\n",
    "#import d2l_utils\n",
    "#from d2l_utils.model import *\n",
    "#from d2l_utils import *\n",
    "#from d2l_utils.train import *\n",
    "#from d2l_utils.train import accuracy\n",
    "\n",
    "# Import utility functions that provide answers to challenges\n",
    "from MLUDTI_EN_M3_Lab4_quiz_questions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the Amazon SageMaker instance has a GPU device available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the output is 'cuda', it's on a GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Load the Fashion-MNIST data\n",
    "train = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "test = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\", train=False, transform=transforms.ToTensor() , download=True\n",
    ")\n",
    "\n",
    "train_iter = data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_iter = data.DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the model evaluation metric and training functions\n",
    "\n",
    "Use the standard code to define the training function that returns the training loss.\n",
    "\n",
    "Because you aren't concerned with model generalization, training loss shows the model's ability to fit a given distribution. Similar graphs for the test loss will show the same phenomenon. More importantly, you will see that this method doesn't learn highly predictive models, and it doesn't learn well-fit models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"../common/images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">The following code cell defines a function to <i>compute the accuracy</i> for the model <b>net</b> on a dataset using a GPU. Review the code, identify how the accuracy is calculated, and then run the cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None): \n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # Number of correct predictions, number of predictions\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for X, y in data_iter:\n",
    "        if isinstance(X, list):\n",
    "            # Required for BERT fine-tuning (to be covered later)\n",
    "            X = [x.to(device) for x in X]\n",
    "        else:\n",
    "            X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        metric.add(d2l.accuracy(net(X), y), d2l.size(y))\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"../common/images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">The following code cell defines the function that <i>trains</i> the model <b>net</b> using a GPU. Review the code, identify where it uses the accuracy evaluation function, and then run the cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, num_epochs, device=d2l.try_gpu()):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            X = X.squeeze(1)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = evaluate_accuracy_gpu(net, train_iter)\n",
    "        train_losses.append(train_loss)\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Design the residual layer\n",
    "\n",
    "Now it's time to implement a simple residual layer with batch normalization. In this case, the input is passed through a dense layer and then through a batch norm layer. This is then fed through ReLU, then another dense layer and batch norm before being added to the original input. These blocks can be made arbitrarily complex, and you can add in tools such as dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MinResidual(nn.Module):\n",
    "    def __init__(self, hidden_size, **kwargs):\n",
    "        super(MinResidual, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X + self.bn2(self.dense2(F.relu(self.bn1(self.dense1(X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"../common/images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">To test your understanding of skip connections in residual layers, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to display the question and check your answer\n",
    "question_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"../common/images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">To test your understanding of a residual block, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to display the question and check your answer\n",
    "question_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have built the residual layer, you will train and evaluate two models. The models will be identical except for the omission of the residual connection on one. After training completes, you will review the report on the final error of both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compare the performance of different residual layers\n",
    "\n",
    "To see how depth impacts training, create plots over a variety of depths to see how they compare after a single epoch of training.\n",
    "\n",
    "__Note:__ The network with residual connections performs much better than the one with dense connections, even after a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encapsulate everything in a function so you can easily change L later\n",
    "def compare_residual(L = 1, epochs = 10) :\n",
    "    # Model definition with BatchNormalization\n",
    "    layers_res = []\n",
    "    layers_res.append(nn.Flatten())\n",
    "    layers_res.append(nn.Linear(28*28, 32))\n",
    "    for l in range(L):\n",
    "        layers_res.append(MinResidual(32))\n",
    "    layers_res.append(nn.Linear(32, 10))\n",
    "    net_res = nn.Sequential(*layers_res)\n",
    "\n",
    "    # Model definition without normalization\n",
    "    layers = []\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Linear(28*28, 32))\n",
    "    for l in range(L):\n",
    "        layers.append(nn.Linear(32, 32))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(32, 32))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.Linear(32, 10))\n",
    "    net = nn.Sequential(*layers)\n",
    "\n",
    "    # Test performance\n",
    "    history_res = train(net_res, train_iter, test_iter, num_epochs = epochs)\n",
    "    history = train(net, train_iter, test_iter, num_epochs = epochs)\n",
    "\n",
    "    return history_res[-1], history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\"> \n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <p style=\"text-align:center; margin:auto;\"><img src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following code cell, write a line of code to compare the performance of these two models (set L=1 and epochs=1).</p>\n",
    "    <br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############### CODE HERE ###############\n",
    "compare_residual(1, 1)\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that, with one layer after a single epoch, both models perform similarly well.\n",
    "\n",
    "To see how the residual model performs compared to the dense model as layers are added, calculate the accuracy for each model as the number of layers are increased to a total of 5. Then, plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "finals = [compare_residual(i,1) for i in range(5)]\n",
    "plt.plot([x[0] for x in finals], label = \"Residual\")\n",
    "plt.plot([x[1] for x in finals], label = \"Dense\")\n",
    "plt.xlabel(\"Layers\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of epochs helps with the gap between models. However, the separation between the two accuracies remains no matter how long the network is trained for. Residual connections ensure that simple solutions can be found at arbitrary depth, while also allowing the model to become more complex if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"../common/images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">To test your understanding of improving the performance of residual layers, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "\n",
    "In this Lab, you saw how to implement residual layers and how to use them to improve the performance of deep neural networks. You also saw how to compare their performance with dense connections on the Fashion-MNIST dataset.\n",
    "\n",
    "By plotting the figure over a variety of depths and comparing the accuracy after a single epoch of training, you observed that the network with residual connections performed better than the network with dense connections, even after a single epoch.\n",
    "\n",
    "Although increasing the number of epochs helps to close the gap, the separation between the two accuracies remains no matter how long the network is trained for.\n",
    "\n",
    "Residual layers and networks are a valuable addition to deep learning, especially for tasks that involve complex and highly nonlinear patterns, such as image classification.\n",
    "\n",
    "--- \n",
    "## Next lab\n",
    "In the next lab, you will learn how to build a model using a modern ConvNeXt architecture with PyTorch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
