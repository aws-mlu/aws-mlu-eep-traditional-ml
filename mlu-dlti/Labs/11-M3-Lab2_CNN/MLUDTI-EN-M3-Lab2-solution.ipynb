{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec25577c-4d60-4ab3-b239-a4776859d66c",
   "metadata": {},
   "source": [
    "<center><img src=\"../common/images/logo.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# Application of Deep Learning to Text and Image Data\n",
    "## Module 3, Lab 2: Using a CNN for Basic Image Operations\n",
    "\n",
    "This notebook will show you how to perform basic image operations on a dataset. Then, you will build a convolutional neural network (CNN) by using built-in CNN architectures in [PyTorch](https://pytorch.org/docs/stable/index.html) to train a multiclass classification model on a real-world dataset. You will also examine the effect of adding layers to a neural network.\n",
    "\n",
    "You will learn how to do the following:\n",
    "\n",
    "- Import data.\n",
    "- Apply padding and stride to data.\n",
    "- Create a neural network.\n",
    "- Add layers to a neural network.\n",
    "- Evaluate the performance of a neural network.\n",
    "\n",
    "----\n",
    "\n",
    "You will be presented with a challenge at the end of this lab:\n",
    "\n",
    "| <img style=\"float: center;\" src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"125\"/> |\n",
    "| --- |\n",
    "| <p style=\"text-align:center;\">Challenges are where you can practice your coding skills.</p> |\n",
    "\n",
    "Note: Images in this lab were reproduced from work created and shared by D2L, https://d2l.ai, and used according to terms described in the Creative Commons 4.0 Attribution License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c780202-faaa-4cd2-91c8-5ecd6809c60b",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## What is a CNN?\n",
    "\n",
    "Before you build a CNN, let's briefly discuss what a CNN is and how it works. A CNN is a type of neural network that is commonly used for image classification, object detection, and other computer vision (CV) tasks. A CNN consists of several layers, including convolutional layers, pooling layers, and fully connected layers.\n",
    "\n",
    "Convolutional layers are the heart of a CNN. They use a set of learnable filters to scan the input image and extract features. Pooling layers then reduce the size of the feature maps that the convolutional layers produce. Finally, the fully connected layers use these features to make predictions about the input image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c25867-c6b4-4e99-92c5-ff42954e3534",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- [Toy example](#Toy-example)\n",
    "- [Real-world example: CIFAR-10](#Real-world-example:-CIFAR-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c56c6-cd32-4031-90cc-9d07ae8fcccc",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Toy example\n",
    "\n",
    "First, look at a sample tensor that you can use as a toy example to understand the concepts of convolution and pooling. \n",
    "Note: The \"toy example\" here is a simplified and small-scale representation of basic image operations. It's used for initial exploration based on simple data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b86e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install libraries\n",
    "!pip install -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4d188-7e84-4412-acb0-6322e0e9e608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd7d71-3c37-40db-a298-9c08b4d4498f",
   "metadata": {},
   "source": [
    "### Convolution 2D\n",
    "\n",
    "The built-in CNN classes in PyTorch have a variety of convolutional layers, such as the following:\n",
    "\n",
    "```python\n",
    "nn.Conv1d()\n",
    "nn.Conv2d()\n",
    "nn.Conv3d()\n",
    "```\n",
    "\n",
    "For more information, see [Convolution Layers](https://pytorch.org/docs/stable/nn.html#convolution-layers) on the torch.nn page in the PyTorch documentation.\n",
    "\n",
    "To improve results, apply padding and stride. Recall that padding adds rows or columns around the input. In the following example, padding of 1 is added to each side:\n",
    "\n",
    "![Padding.](https://d2l.ai/_images/conv-pad.svg)\n",
    "\n",
    "\n",
    "Stride refers to the number of units that the kernel shifts in each direction per step. In the following example, a stride of (2,3) is used:\n",
    "\n",
    "![Stride.](https://d2l.ai/_images/conv-stride.svg)\n",
    "\n",
    "Start by creating a sample tensor with shape (3, 3), kernel size of 2, padding size of 1, and stride size of (2, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998053c2-5d5f-4b06-8fa7-78e2d2dc04fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a tensor\n",
    "X = torch.rand(size=(3, 3))\n",
    "\n",
    "# Create a 2D convolution\n",
    "conv2d = nn.Conv2d(\n",
    "    in_channels=1, out_channels=1, kernel_size=2, padding=1, stride=(2, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8623c0-7bc4-469d-a7e8-7d783b55ef9b",
   "metadata": {},
   "source": [
    "### Computing the shape\n",
    "\n",
    "Now you need to determine what the resulting shape of the tensor is after the updates to the `Conv2d` class were applied.\n",
    "\n",
    "The output shape of `Conv2d()` should be the following:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{ Output shape} & = \\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor \\\\\n",
    " & = \\lfloor(3 - 2 + 2*1 + 2) / 2\\rfloor \\times \\lfloor(3 - 2 + 2*1 + 3) / 3\\rfloor \\\\\n",
    " & = (2, 2)\n",
    "\\end{align}\n",
    "\n",
    "You can validate this in code. To check the output of the convolution layers, define the `comp_conv2d` function as forward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50d79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d, X):\n",
    "    # Reshaping with (1, 1) specifies batch size and number of channels\n",
    "    # Batch of 1 image is processed, and the input image is assumed to be a grayscale image (1 channel)\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    print(\"Input shape:\", X.shape)\n",
    "    Y = conv2d(X)\n",
    "    print(\"Output shape:\", Y.shape)\n",
    "    # Exclude the first two dimensions that aren't of interest:\n",
    "    # examples and channels\n",
    "    return Y.reshape(Y.shape[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b486ac0-9e87-4d38-b816-78d1e9b15c04",
   "metadata": {},
   "source": [
    "Now that you created this function, you can use it to verify the output shape of the Conv2D layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c375db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802755e-5cb6-4949-be9a-e8cee717470e",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "\n",
    "Recall that max pooling returns the maximal value in the pooling window, while average pooling returns the mean.\n",
    "\n",
    "![Pooling.](https://d2l.ai/_images/pooling.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1377948-e3b7-442d-846b-c83de6fc40c5",
   "metadata": {},
   "source": [
    "You can also import a built-in pooling layer from PyTorch with padding and stride. Some examples are `MaxPool2d()` and `AvgPool1d()`.\n",
    "\n",
    "For more information, see [Pooling Layers](https://pytorch.org/docs/stable/nn.html#pooling-layers) on the torch.nn page in the PyTorch documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e333ad84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new sample tensor with 4 rows and 4 columns\n",
    "# The values inside the tensor range from 0 to 15\n",
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "print(X)\n",
    "\n",
    "# Apply the pooling\n",
    "pool2d = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "print(pool2d(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc2123-4a9f-455a-bf65-b870029e35ea",
   "metadata": {},
   "source": [
    "---\n",
    "## Real-world example: CIFAR-10\n",
    "\n",
    "Now that you have explored the key concepts of convolution, you can use what you have learned to build a simple CNN to process some real-world data. To do this, you will load the dataset, design the network, and finally evaluate the network's performance.\n",
    "\n",
    "You will use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). This image dataset has the following classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. The images in the CIFAR-10 dataset are of size 3x32x32, which means that they are 3-channel color images that are 32x32 pixels in size.\n",
    "\n",
    "The following image provides a sample of images from each class in the dataset:\n",
    "\n",
    "![CIFAR10 Examples.](https://pytorch.org/tutorials/_images/cifar10.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3571ed-0505-471b-a2a2-416c450d666d",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading the dataset\n",
    "\n",
    "To load the dataset, you need to prepare the image data a bit by using `transfom` functions.\n",
    "\n",
    "First, convert the image tensor of shape (C x H x W) in the range [0, 255] to a `float32` torch tensor of shape (C x H x W) in the range [0, 1] by using the `ToTensor` class. Then, normalize a tensor of shape (C x H x W) with its mean and standard deviation by using the `Normalize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144174ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformation = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(mean=(0, 0, 0), std=(1, 1, 1))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a5e216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transformation\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transformation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d9858-0ec2-41c6-bf2e-15698ccfcf26",
   "metadata": {},
   "source": [
    "It's helpful to visualize what the dataset looks like. To do this, define a `show_images` function, and then use the function to display sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e8a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function to load images and display them\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    \"\"\"Plot a list of images.\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        ax.imshow(img.permute(1, 2, 0).numpy())\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f3860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use DataLoader to get sample images\n",
    "sample = DataLoader(train_dataset, batch_size=2 * 8, shuffle=True)\n",
    "\n",
    "# Use the loaded images with the show_images function to display them\n",
    "for data, label in sample:\n",
    "    show_images(data, 2, 8)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5b1e5-e6e5-406d-bdc6-382f8716cbb3",
   "metadata": {},
   "source": [
    "In practice, reading in or plotting images can be a significant performance bottleneck. To facilitate the processing of reading images from the datasets, use a PyTorch `DataLoader`. The `DataLoader` reads a minibatch of data with size `batch_size` each time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883c269-0f44-4ef0-bfe0-3130f25334e3",
   "metadata": {},
   "source": [
    "Before building the convolutional network, you need to set up the `DataLoader` and split the training dataset into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb2ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the batch size for the minibatches\n",
    "batch_size = 16\n",
    "\n",
    "# Define the percentage of the dataset that you want in the validation set\n",
    "valid_size = 0.2\n",
    "\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "# Split the dataset\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# Load the training data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=train_sampler,\n",
    ")\n",
    "\n",
    "# Load the validation data\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=valid_sampler,\n",
    ")\n",
    "\n",
    "# Create minibatches\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7e4e55-bbf7-404c-82db-a00336c39ee7",
   "metadata": {},
   "source": [
    "---\n",
    "## Designing the network\n",
    "\n",
    "Now that you have seen the data, it's time to design a CNN.\n",
    "\n",
    "First, initialize a `Sequential` block. In PyTorch, `Sequential` defines a container for several layers that will be chained together. Given input data, a `Sequential` block passes it through the first layer, in turn passing the output as the second layer's input and so forth.\n",
    "\n",
    "You will build a neural network with a 2D convolutional layer, `Conv2D(in_channels=3, out_channels=16, kernel_size=5)`. This will be followed by a 2D max pooling layer, `MaxPool2d(kernel_size=2, stride=2)`; a fully connected (or `Dense`) layer; and a final output `Dense` layer with output classes 10 (because CIFAR-10 contains 10 different classes). Use `ReLU` as the activation function between layers.\n",
    "\n",
    "To get the correct dimensions for the final dense layer, consider what the various transformations have done to the input size of the image. You might want to create a helper function to calculate the output shape; the final result should be `nn.Linear(14 * 14 * 16, 32)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08568a4d-afd3-41f6-95c9-e7fa8c1fdebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create helper function to calculate the image size after applying layers\n",
    "def maxpool(w, k, p=0, d=1, s=None):\n",
    "    return ((w + 2 * p - d * (k - 1) - 1) / s) + 1\n",
    "\n",
    "\n",
    "# Create helper function to calculate the image size after applying layers\n",
    "def conv2d(w, k, p=0, d=1, s=1):\n",
    "    return ((w - k + 2 * p) / s) + 1\n",
    "\n",
    "\n",
    "maxpool(w=conv2d(32, 5), k=2, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a045d37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use GPU resource, if available; otherwise, use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the number of output classes\n",
    "out_classes = 10\n",
    "\n",
    "# Design the network\n",
    "net = nn.Sequential(\n",
    "    # Convolutional layer\n",
    "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    # Max pooling layer\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    # The flatten layer collapses all axes,\n",
    "    # except the first one, into one axis.\n",
    "    nn.Flatten(),\n",
    "    # Fully connected or dense Layer\n",
    "    nn.Linear(14 * 14 * 16, 32),\n",
    "    nn.ReLU(),\n",
    "    # Output layer\n",
    "    nn.Linear(32, out_classes),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bacb3f-cbe3-4767-aee9-e5ea93a9eb76",
   "metadata": {},
   "source": [
    "The network is almost ready to be trained. The last thing to do before training is to set the number of epochs to train, the learning rate of optimization algorithms, and the loss function. Because this problem is a multiclass classification task, `CrossEntropyLoss` is the correct loss function to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66485c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "learning_rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af68470c-3029-49fd-bb56-557c5a42cd6e",
   "metadata": {},
   "source": [
    "To calculate the accuracy easily, define a function, `calculate_accuracy(output, label)`, that can be called for each batch of data. The function uses the network's outputs and the corresponding labels to calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a71b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(output, label):\n",
    "    \"\"\"Calculate the accuracy of the trained network.\n",
    "    output: (batch_size, num_output) float32 tensor\n",
    "    label: (batch_size, ) int32 tensor\"\"\"\n",
    "\n",
    "    return (output.argmax(axis=1) == label.float()).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94ec1f-3691-4373-8201-838c34278ab1",
   "metadata": {},
   "source": [
    "To get the neural network to optimize its weights, instantiate by using `optim.<Optimizer>`. This defines the parameters to optimize over (obtainable from the neural network by using `net.parameters()`) and the hyperparameters that the optimization algorithm requires. After you do that, it's time to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d2097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net = net.to(device)\n",
    "\n",
    "    train_loss, val_loss, train_acc, valid_acc = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    # Training loop\n",
    "    # This loop trains the neural network (weights are updated)\n",
    "    net.train()  # Activate training mode\n",
    "    for data, label in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Put data and label to the correct device\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        # Make forward pass\n",
    "        output = net(data)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, label)\n",
    "        # Make backward pass (calculate gradients)\n",
    "        loss.backward()\n",
    "        # Accumulate training accuracy and loss\n",
    "        train_acc += calculate_accuracy(output, label).item()\n",
    "        train_loss += loss.item()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    # This loop tests the trained network on the validation dataset\n",
    "    # No weight updates here\n",
    "    # torch.no_grad() reduces memory usage when not training the network\n",
    "    net.eval()  # Activate evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for data, label in valid_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            # Make forward pass with the trained model so far\n",
    "            output = net(data)\n",
    "            # Accumulate validation accuracy and loss\n",
    "            valid_acc += calculate_accuracy(output, label).item()\n",
    "            val_loss += criterion(output, label).item()\n",
    "\n",
    "    # Take averages\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "    val_loss /= len(valid_loader)\n",
    "    valid_acc /= len(valid_loader)\n",
    "\n",
    "    print(\n",
    "        \"Epoch %d: train loss %.3f, train acc %.3f, val loss %.3f, val acc %.3f\"\n",
    "        % (epoch + 1, train_loss, train_acc, val_loss, valid_acc)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b2ae2-b46e-4c84-9157-1ad633015170",
   "metadata": {},
   "source": [
    "Notice that the training loss and accuracy continue to improve, while the validation loss and accuracy are mostly fluctuating. This is a signal of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702980c2-9784-43ca-9dc7-6f579a71778c",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluating the network\n",
    "\n",
    "Now that you have trained the model, you can test its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69135bec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_acc = 0.0\n",
    "\n",
    "# Activate evaluation mode\n",
    "net.eval()  \n",
    "\n",
    "# Calculate the test accuracy\n",
    "with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        output = net(data)\n",
    "        test_acc += calculate_accuracy(output, label).item()\n",
    "\n",
    "# Calculate the average test accuracy\n",
    "test_acc = test_acc / len(test_loader)\n",
    "\n",
    "print(\"Test accuracy: %.3f\" % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1f385-4340-43d0-b53e-eb1c71bbdb47",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <img style=\"float: center;\" src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"100\" />\n",
    "    <p style=\"text-align: center; margin: auto;\">Modify the neural network to create an <code>updated_net</code> that includes a second <code>Conv2d(in_channels=3, out_channels=16, kernel_size=5)</code> followed by a <code>MaxPool2d(kernel_size=2, stride=2)</code> layer. Continue to use <code>ReLU</code> as the activation function.</p><br>\n",
    "    <p style=\"text-align: center; margin: auto;\">Ensure that you update the dimensions in the dense layer to account for the additional convolution and pooling.</p><br>\n",
    "    <p style=\"text-align: center; margin: auto;\">You will also need to update the optimizer: <code>updated_optimizer = SGD(updated_net.parameters(), lr=learning_rate)</code>.</p><br>\n",
    "    <p style=\"text-align: center; margin: auto;\">Retrain the network, and evaluate on the test data. Has the performance improved?</p><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d40932-03c2-4cc6-b81f-e649e43db5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############### CODE HERE ###############\n",
    "\n",
    "# Updated network\n",
    "updated_net = nn.Sequential(\n",
    "    # First convolution layer\n",
    "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    # First max pooling layer\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    # Second convolution layer\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    # Second max pooling layer\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    # The flatten layer collapses all axes,\n",
    "    # except the first one, into one axis\n",
    "    nn.Flatten(),\n",
    "    # Fully connected or dense Layer\n",
    "    nn.Linear(5 * 5 * 16, 32),\n",
    "    nn.ReLU(),\n",
    "    # Output layer\n",
    "    nn.Linear(32, out_classes),\n",
    ").to(device)\n",
    "\n",
    "# Updated optimizer\n",
    "updated_optimizer = SGD(updated_net.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training and validating the network\n",
    "for epoch in range(epochs):\n",
    "    updated_net = updated_net.to(device)\n",
    "\n",
    "    train_loss, val_loss, train_acc, valid_acc = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    # Training loop\n",
    "    # This loop trains the neural network (weights are updated)\n",
    "    updated_net.train()  # Activate training mode\n",
    "    for data, label in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        updated_optimizer.zero_grad()\n",
    "        # Put data and label to the correct device\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        # Make forward pass\n",
    "        output = updated_net(data)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, label)\n",
    "        # Make backward pass (calculate gradients)\n",
    "        loss.backward()\n",
    "        # Accumulate training accuracy and loss\n",
    "        train_acc += calculate_accuracy(output, label).item()\n",
    "        train_loss += loss.item()\n",
    "        # Update weights\n",
    "        updated_optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    # This loop tests the trained network on the validation dataset\n",
    "    # No weight updates here\n",
    "    # torch.no_grad() reduces memory usage when not training the network\n",
    "    updated_net.eval()  # Activate evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for data, label in valid_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            # Make forward pass with the trained model so far\n",
    "            output = updated_net(data)\n",
    "            # Accumulate validation accuracy and loss\n",
    "            valid_acc += calculate_accuracy(output, label).item()\n",
    "            val_loss += criterion(output, label).item()\n",
    "\n",
    "    # Take averages\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "    val_loss /= len(valid_loader)\n",
    "    valid_acc /= len(valid_loader)\n",
    "\n",
    "    print(\n",
    "        \"Epoch %d: train loss %.3f, train acc %.3f, val loss %.3f, val acc %.3f\"\n",
    "        % (epoch + 1, train_loss, train_acc, val_loss, valid_acc)\n",
    "    )\n",
    "\n",
    "# Testing the network\n",
    "test_acc = 0.0\n",
    "updated_net.eval()  # Activate evaluation mode\n",
    "with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        output = updated_net(data)\n",
    "        test_acc += calculate_accuracy(output, label).item()\n",
    "\n",
    "test_acc = test_acc / len(test_loader)\n",
    "\n",
    "print(\"Test accuracy: %.3f\" % test_acc)\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f32ab-1bf2-44bc-bdc5-12b240e42d76",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, you practiced building a CNN. You learned that making the neural network more sophisticated by adding layers doesn't necessarily improve the performance. This tells you that a different type of neural network might be better suited to solve the image classification task.\n",
    "\n",
    "--- \n",
    "## Next lab\n",
    "In the next lab, you will continue to learn about CNNs by using PyTorch to process a real-world dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
