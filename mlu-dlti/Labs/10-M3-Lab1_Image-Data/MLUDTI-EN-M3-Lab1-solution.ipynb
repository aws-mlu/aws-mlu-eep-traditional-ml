{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec25577c-4d60-4ab3-b239-a4776859d66c",
   "metadata": {},
   "source": [
    "<center><img src=\"../common/images/logo.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# Application of Deep Learning to Text and Images\n",
    "## Module 3, Lab 1: Reading image data to find descriptors and create plots\n",
    "\n",
    "This notebook will show you how to open and read image data using Python and PyTorch, extract features from images and you will learn how to plot images.\n",
    "\n",
    "You will learn the following:\n",
    "\n",
    "- How to import image data\n",
    "- How to extract features from image data\n",
    "- How to plot image data\n",
    "\n",
    "----\n",
    "\n",
    "You will be presented withz challenges throughout the notebook: <br/>\n",
    "\n",
    "| <img style=\"float: center;\" src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"125\"/>|\n",
    "| --- |\n",
    "|<p style=\"text-align:center;\">Challenges are where you can practice your coding skills.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac70654-85f7-4e72-94fb-998fe6970a77",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- [Reading Images](#Reading-Images)\n",
    "- [Inspecting Images](#Inspecting-Images)\n",
    "- [Extracting Features](#Extracting-Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a01c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# installing libraries\n",
    "!pip install -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4d188-7e84-4412-acb0-6322e0e9e608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, \"..\")\n",
    "from MLUDTI_EN_M3_Lab1_quiz_questions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c56c6-cd32-4031-90cc-9d07ae8fcccc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading Images\n",
    "In this section you are going to learn how to open images using Python and how to inspect those images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad4065-11b2-4639-aaee-bbd9eec17b5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PyTorch Image Datasets\n",
    "\n",
    "First, load the CIFAR10 data. This is one of many image datasets that can be loaded in directly with `torchvision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c8d2c-3b0d-45f5-866e-6dfba1a58ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Get the training images\n",
    "img_train = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "# Get the test images\n",
    "img_test = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec99fe-8d51-4e9c-ac93-e46892b5f6d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inspecting an Image\n",
    "\n",
    "You can look at one example data point by specifying the ID of the image you want to retrieve. As result, you get a tuple of `(image, label)`. If you call `image.shape` you can see how many color channels the image contains, the height, and width: `[color channels, height, width]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f499b0-d186-49e2-9d49-9831d0583431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the image and label at the 42nd index\n",
    "image, label = img_train[42]\n",
    "print(image.shape, \"Label: \",label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ceaaac-abcc-4774-b17e-4a3a386ab0c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "The output above tells you 4 things:\n",
    "1. This is a color image with __3__ channels.\n",
    "1. The height of the image is __32__ px.\n",
    "1. The width of the image is __32__ px.\n",
    "1. Time image lable is __2__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b255ad-5130-4920-9be8-3e537e0dcc16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Images as Tensors\n",
    "\n",
    "PyTorch has a constructor that creates a `Dataset` object from a list of tensors similar to what you saw above: \n",
    "\n",
    "`torch.utils.data.TensorDataset`\n",
    "\n",
    "This is simply a tensor data construct that allows you to access individual images (or batches of images) and their labels easily.\n",
    "\n",
    "To create a TensorDataset you need to pass the images (data_tensor) and labels (target_tensor) into `Dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092a721-9088-49d2-8265-a72076a07f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take the first 50 example images from the training \n",
    "# dataset and their corresponding labels\n",
    "\n",
    "data_tensor = torch.Tensor(img_train.data[:50])\n",
    "target_tensor = torch.Tensor(img_train.targets[:50])\n",
    "\n",
    "tensor_dataset = TensorDataset(data_tensor, target_tensor)\n",
    "\n",
    "print(tensor_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966be0e3-8e23-4542-a8c6-26c0e15b0165",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading an Image Dataset\n",
    "\n",
    "Now that you have created a PyTorch tensor dataset, you need to learn what you can do with it. The first question is, how can you access individual or multiple images in the tensor dataset? \n",
    "\n",
    "Images can be accessed using a dataloader. `torch.utils.data.DataLoader` takes a `TensorDataset` object as input, and allows you to iterate through minibatches of your data. \n",
    "\n",
    "`torch.utils.data.DataLoader` has arguments such as:\n",
    "\n",
    "* `batch_size` - sets the batch size\n",
    "* `shuffle` - boolean that determines whether to vend the data in a random order, or iterate in order\n",
    "* `drop_last` - set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch might be smaller. This can be helpful if your models requires batches to be exactly the same size for each iteration. \n",
    "\n",
    "Now, use the tensor dataset you created with 50 example images with a `DataLoader` to create batches of `32` images from the CIFAR10 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303e848-f9b4-4616-b9a3-4e1a6d659eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    tensor_dataset, batch_size=32, shuffle=True, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78721e7c-916c-4ced-a21b-f024da154e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data, labels in dataloader:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a5881",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>It's time to check your knowledge!</i></h3>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856f2d6-0851-4173-88f8-9b58bbbbb7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1f385-4340-43d0-b53e-eb1c71bbdb47",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h2><i>Try it Yourself!</i></h2>\n",
    "    <br>\n",
    "    <img style=\"float: center;\" src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"100\" />\n",
    "    <p style=\"text-align: center; margin: auto;\">Update the <code>DataLoader</code> code and set <code>drop_last=True</code>. </p>\n",
    "    <p style=\"text-align: center; margin: auto;\">How many batches do you think will be created? Check your answer</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac11eaf-ce9d-45b3-8b79-e398dbdfb09d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dataloader that drops incomplete batches and \n",
    "# print the data shapes for each batch\n",
    "########## CODE HERE ##########\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    tensor_dataset, batch_size=32, shuffle=True, drop_last=True\n",
    ")\n",
    "\n",
    "for data, labels in dataloader:\n",
    "    print(data.shape)\n",
    "\n",
    "########## END OF CODE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665358b0-4a87-4a78-8b91-fa4b5a8ec459",
   "metadata": {},
   "source": [
    "## Inspecting Images\n",
    "\n",
    "Now that you have loaded the images and created batches you are ready to inspect the images. This next section will show you how to separate images into different color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab9538-a7b9-4f49-9f89-ae358a3521c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can convert from an an image object to an array using np.asarray\n",
    "# to be able to look at the pixel values and manipulate them\n",
    "img_array = np.asarray(image)\n",
    "# Print the pixel values\n",
    "print(img_array)\n",
    "\n",
    "# Given the tensor representing the image, \n",
    "# use .permute() to put the channels as the last dimension:\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "\n",
    "# Check that the color ordering matches what is expect (RGB)\n",
    "\n",
    "# Zeroing out channels 1 and 2 should show the red color channel \n",
    "# Note: Remember that Python uses 0 index so the red channel is number 0\n",
    "red = image.permute(1, 2, 0).detach().clone()\n",
    "\n",
    "red[:, :, 1] = 0\n",
    "red[:, :, 2] = 0\n",
    "plt.imshow(red)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a7cfe-2258-4931-8f47-344ea89f095c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Zero out channels 0 and 2 to see an image with green hues\n",
    "\n",
    "green = image.permute(1, 2, 0).detach().clone()\n",
    "\n",
    "green[:, :, 0] = 0\n",
    "green[:, :, 2] = 0\n",
    "\n",
    "plt.imshow(green)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4605084f-3277-4f38-9683-7ed6d83354c1",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h2><i>Try it Yourself!</i></h2>\n",
    "    <br>\n",
    "    <img style=\"float: center;\" src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"100\" />\n",
    "    <p style=\"text-align: center; margin: auto;\">Print an image with only blue hues.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071c0d6-b6ec-45c1-9f1f-190b2ab1aa2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Zero out the correct channels to see an image with blue hues\n",
    "########## CODE HERE ##########\n",
    "\n",
    "blue = image.permute(1, 2, 0).detach().clone()\n",
    "\n",
    "blue[:, :, 0] = 0\n",
    "blue[:, :, 1] = 0\n",
    "\n",
    "plt.imshow(blue)\n",
    "\n",
    "########## END OF CODE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e9fe13-4daa-497d-9d95-6fd35a5c5b9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extracting Features\n",
    "\n",
    "The next step is to learn how to extract features from the image. You can do this by applying a convolutional layer and a Laplace filter. The Laplacian of an image highlights regions of rapid intensity change and is therefore often used for edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405e79fe-4efe-4913-a742-c335b2fc39f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a convolutional layer using PyTorch\n",
    "conv2d = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c914d0-193a-4c56-b921-1d660e3fdedb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the resulting feature map as a grayscale image\n",
    "plt.imshow(conv2d(image).permute(1, 2, 0).detach().numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6002345-6436-41f4-9db2-70a4e240bce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use nn.Conv2d to apply a 3x3 Laplace filter to the image\n",
    "laplace = torch.Tensor([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\n",
    "laplace_kernel = torch.stack((laplace, laplace, laplace), dim=0).unsqueeze(0)\n",
    "\n",
    "# Set weights of convolutional layer to the Laplace kernel\n",
    "laplace_conv2d = nn.Conv2d(\n",
    "    in_channels=3, out_channels=1, kernel_size=3, padding=1, bias=False\n",
    ")\n",
    "laplace_conv2d.weight.data = laplace_kernel\n",
    "laplace_conv2d.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e717f-b48c-4088-a461-15409bc64cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the resulting feature map as a grayscale image\n",
    "plt.imshow(laplace_conv2d(image).permute(1, 2, 0).detach().numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf511c03",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>It's time to check your knowledge!</i></h3>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec95965-bcad-4835-ac11-6984867ba811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e4f74-3517-49be-a480-10045b7a1727",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h2><i>Try it Yourself!</i></h2>\n",
    "    <br>\n",
    "    <img style=\"float: center;\" src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"100\" />\n",
    "    <p style=\"text-align: center; margin: auto;\">Try to create a new filter using a sharpening kernel:\n",
    "\\begin{bmatrix}\n",
    "\\ \\ 0 & -1 & \\ \\ 0 \\\\\n",
    "-1 & \\ \\ 5 & -1 \\\\\n",
    "\\ \\ 0 & -1 & \\ \\ 0\n",
    "\\end{bmatrix}\n",
    ".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db39020-3415-464f-9df7-3efe5d1ccb7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a tensor that holds the sharpening kernel\n",
    "# Then set the weights of the convolutional to use the sharpening kernel\n",
    "########## CODE HERE ##########\n",
    "\n",
    "### Let's use nn.Conv2d to apply a 3x3 sharpening filter to the image\n",
    "sharpening = torch.Tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "sharpening_kernel = torch.stack((sharpening, sharpening, sharpening), dim=0).unsqueeze(\n",
    "    0\n",
    ")\n",
    "\n",
    "# Set weights of convolutional layer to the sharpening kernel\n",
    "sharpening_conv2d = nn.Conv2d(\n",
    "    in_channels=3, out_channels=1, kernel_size=3, padding=1, bias=False\n",
    ")\n",
    "sharpening_conv2d.weight.data = sharpening_kernel\n",
    "sharpening_conv2d.weight.requires_grad = False\n",
    "\n",
    "# Plot the resulting feature map as a grayscale image\n",
    "plt.imshow(sharpening_conv2d(image).permute(1, 2, 0).detach().numpy(), cmap=\"gray\")\n",
    "\n",
    "########## END OF CODE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a22211-be08-439b-99ad-476ed745fff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Every kernel will have a different impact on the image. The Laplace and sharpening kernels are well know and commonly used, but there are many others you can try to enhance the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678f677-5650-4c58-91e7-5e920aa73a88",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "\n",
    "This notebook is meant to be a quick way to get you up-to-speed with loading images, creating `TensorDatasets` and extracting features from images using simple filters.\n",
    "\n",
    "--- \n",
    "## Next Lab: The concept of convolution\n",
    "In the next lab, you will learn how to build a Convolutional Neural Network (CNN) by using built-in CNN architectures in [PyTorch](https://pytorch.org/docs/stable/index.html) to train a multiclass classification model on a real-world dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
