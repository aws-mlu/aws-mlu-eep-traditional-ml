{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../common/images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"600\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# Application of Deep Learning to Text and Image Data\n",
    "## Module 3, Lab 3: Implementing a CNN by Using PyTorch\n",
    "\n",
    "This hands-on notebook will show you how to build a convolutional neural network (CNN) by using PyTorch. \n",
    "\n",
    "You will learn how to do the following:\n",
    "\n",
    "- Use built-in PyTorch CNN architectures to train a multiclass classification model.\n",
    "- Design a CNN model architecture.\n",
    "- Train a model by using a CNN.\n",
    "- Evaluate performance of a CNN model.\n",
    "\n",
    "---\n",
    "\n",
    "You will be presented with two kinds of exercises throughout the notebook: activities and challenges. <br/>\n",
    "\n",
    "| <img style=\"float: center;\" src=\"../common/images/activity.png\" alt=\"Activity\" width=\"125\"/>| <img style=\"float: center;\" src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"125\"/>|\n",
    "| --- | --- |\n",
    "|<p style=\"text-align:center;\">No coding is needed for an activity. You try to understand a concept, <br/>answer questions, or run a code cell.</p> |<p style=\"text-align:center;\">Challenges are where you can practice your coding skills.</p> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Index\n",
    "\n",
    "- [Introduction of a real-world example](#Introduction-of-a-real-world-example)\n",
    "- [Load the dataset](#Load-the-dataset)\n",
    "- [Design the model architecture](#Design-the-model-architecture)\n",
    "- [Define the loss function, optimizer, and evaluation metric](#Define-the-loss-function,-optimizer,-and-evaluation-metric)\n",
    "- [Train the model](#Train-the-model)\n",
    "- [Evaluate the model](#Evaluate-the-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install libraries\n",
    "!pip install -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Introduction of a real-world example\n",
    "\n",
    "The [Materials in Context Database (MINC)](http://opensurfaces.cs.cornell.edu/publications/minc) from Cornell University is a large-scale dataset of images of real-world materials. This lab uses a subset of the MINC dataset. The dataset is well-labeled and a moderate size, which makes it a good fit for this example.\n",
    "\n",
    "Reference: Sean Bell, Paul Upchurch, Noah Snavely, and Kavita Bala. \"Material Recognition in the Wild with the Materials in Context Database.\" *Computer Vision and Pattern Recognition (CVPR)*, April 2015. https://arxiv.org/abs/1412.0623.\n",
    "\n",
    "The following image provides examples of images from multiple classes of the dataset.\n",
    "\n",
    "![MINC 2500 Examples by class](../common/images/MINC-2500.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Load the dataset\n",
    "\n",
    "First, load the dataset that you will use to train the CNN model. In this example, you will use the MINC-2500 dataset with the following classes: \n",
    "- Brick\n",
    "- Carpet\n",
    "- Food\n",
    "- Mirror\n",
    "- Sky\n",
    "- Water\n",
    "\n",
    "To start, define the training, validation, and test paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '../data/minc-2500'\n",
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'val')\n",
    "test_path = os.path.join(path, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good practice is to visualize the dataset. To do this, define the `show_images` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    \"\"\"Plot a list of images.\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        ax.imshow(img.permute(1,2,0).numpy())\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"../common/images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\"text-align: center; margin: auto;\">To load sample images from the test data, run the following cell. To see different images, run the cell multiple times.</p><br>\n",
    "    <p style=\"text-align: center; margin: auto;\">To display a 4x4 grid of images, update the call to the <code>show_images</code> function.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder(test_path, transform=transforms.ToTensor())\n",
    "test_sample = DataLoader(test_dataset, batch_size=2*8, shuffle=True)\n",
    "\n",
    "for data, label in test_sample:\n",
    "    show_images(data, 2, 2);\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the dataset, you first need to prepare the image data by using `transfoms` functions as follows:\n",
    "1. Load the image data and resize it to the given size (224,224).\n",
    "1. Convert the image tensor of shape (C x H x W) in the range [0, 255] to a `float32` torch tensor of shape (C x H x W) in the range (0, 1) using the `ToTensor` class.\n",
    "1. Normalize a tensor of shape (C x H x W) with its mean and standard deviation by using the `Normalize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0,0,0), std=(1,1,1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have defined a transformation, you can load the train, validation, and test sets and apply the transformation to them.\n",
    "\n",
    "In practice, reading data can be a significant performance bottleneck, even when the model is simple or when the computer is fast. Loading the data can take more time than training the model. To speed up the process of loading the dataset, use a PyTorch `DataLoader`. A data loader reads a minibatch of data with size `batch_size` each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"../common/images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the train and validation sets, run the following cell.</p><br>\n",
    "    <p style=\" text-align: center; margin: auto;\">For a large dataset, you can adjust the <code>batch_size</code> to improve load speed.</p><br>\n",
    "    <p style=\" text-align: center; margin: auto;\"><b>Note:</b> This dataset is small, and the Amazon SageMaker instance is fast, so adjusting the batch size here would have little impact on the data load.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    ImageFolder(train_path, transform=transformation),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    ImageFolder(val_path, transform=transformation),\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\"> \n",
    "   <h3><i>Try it yourself!</i></h3>\n",
    "    <p style=\"text-align:center; margin:auto;\"><img src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following cell, write code to load the test set.</p>\n",
    "    <br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############### CODE HERE ###############\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    ImageFolder(test_path, transform=transformation),\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Design the model architecture\n",
    "\n",
    "Now you will design a CNN. First, initialize a `Sequential` block. In PyTorch, `Sequential` defines a container for several layers that will be chained together. Given input data, a `Sequential` passes it through the first layer, in turn passing the output as the second layer’s input and so forth.\n",
    "\n",
    "You want to build a neural network with a 2D convolutional layer `Conv2D`, followed by a 2D max pooling layer `MaxPool2D`, a fully connected (or `Dense`) layer, and a final output `Dense` layer with six output classes. The following figure shows a diagram of the CNN architecture that you will build in this notebook.\n",
    "\n",
    "<center><img src=\"../common/images/cnn.png\" width=\"250px\" alt=\"CNN architecture\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use GPU resource if available; otherwise, use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out_classes = 6\n",
    "\n",
    "net = nn.Sequential(\n",
    "    # First convolutional layer\n",
    "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    # First max pooling layer\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    # Second convolutional layer\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    # Second max pooling layer\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    # The flatten layer collapses all axes,\n",
    "    # except the first one, into one axis.\n",
    "    nn.Flatten(),\n",
    "    # Fully connected or dense Layer\n",
    "    nn.Linear(53*53*16, 32),\n",
    "    nn.ReLU(),\n",
    "    # Output layer\n",
    "    nn.Linear(32, out_classes)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the loss function, optimizer, and evaluation metric\n",
    "\n",
    "The neural network is almost ready to be trained. The last thing to do before training is set the hyperparameters, such as training device (GPU or CPU), the number of epochs to train, and the learning rate of the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"../common/images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">To specify the loss function, run the following cell.</p><br>\n",
    "    <p style=\" text-align: center; margin: auto;\">Because this is a multiclass classification task, use <code>CrossEntropyLoss</code> as the loss function. Different problem types use different loss functions. For example, mean squared error (MSE) is commonly used for regression problems.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you need to instantiate the `optim.<Optimizer>`, which defines the parameters to optimize over (which are obtained from the network by using `net.parameters()`) and the hyperparameters that the optimization algorithm requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, define a function to calculate the accuracy, `calculate_accuracy(output, label)`. This function is called for each batch of data. The function uses the network's outputs and the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(output, label):\n",
    "    \"\"\"Calculate the accuracy of the trained network. \n",
    "    output: (batch_size, num_output) float32 tensor\n",
    "    label: (batch_size, ) int32 tensor \"\"\"\n",
    "    \n",
    "    return (output.argmax(axis=1) == label.float()).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"../common/images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">It's time to train the model! Run the following cell.</p><br>\n",
    "    <p style=\" text-align: center; margin: auto;\">This code will train 15 epochs (15 full passes through the dataset).</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    #You set the device in the \"Design the model architecture\" section\n",
    "    net = net.to(device)\n",
    "\n",
    "    train_loss, val_loss, train_acc, valid_acc = 0., 0., 0., 0.\n",
    "\n",
    "    # Training loop\n",
    "    # This loop trains the neural network (weights are updated)\n",
    "    net.train() # Activate training mode\n",
    "    for data, label in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Put data and label to the correct device\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        # Make forward pass\n",
    "        output = net(data)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, label)\n",
    "        # Make backward pass (calculate gradients)\n",
    "        loss.backward()\n",
    "        # Accumulate training accuracy and loss\n",
    "        train_acc += calculate_accuracy(output, label).item()\n",
    "        train_loss += loss.item()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    # This loop tests the trained network on the validation dataset\n",
    "    # No weight updates here\n",
    "    # torch.no_grad() reduces memory usage when not training the network\n",
    "    net.eval() # Activate evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for data, label in validation_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            # Make forward pass with the trained model so far\n",
    "            output = net(data)\n",
    "            # Accumulate validation accuracy and loss\n",
    "            valid_acc += calculate_accuracy(output, label).item()\n",
    "            val_loss += criterion(output, label).item()\n",
    "\n",
    "    # Take averages\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "    val_loss /= len(validation_loader)\n",
    "    valid_acc /= len(validation_loader)\n",
    "\n",
    "    print(\"Epoch %d: train loss %.3f, train acc %.3f, val loss %.3f, val acc %.3f\" % (\n",
    "        epoch+1, train_loss, train_acc, val_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that the training loss and accuracy improve, while the validation loss and accuracy mostly fluctuate. This is a signal of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\"> \n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <p style=\"text-align:center; margin:auto;\"><img src=\"../common/images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following cell, write code that computes the test accuracy by using the evaluation function.</p>\n",
    "    <br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_acc = 0.\n",
    "net.eval() # Activate evaluation mode\n",
    "with torch.no_grad():\n",
    "############### CODE HERE ###############\n",
    "    for data, label in test_loader:\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        output = net(data)\n",
    "        test_acc += calculate_accuracy(output, label).item()\n",
    "############## END OF CODE ##############\n",
    "\n",
    "test_acc = test_acc/len(test_loader)\n",
    "\n",
    "print(\"Test accuracy: %.3f\" % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have designed a CNN model and evaluated its accuracy, you are ready to build a model with a more modern architecture that performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "\n",
    "In this lab, you learned the basic steps to build a CNN by using PyTorch. You began by importing the necessary packages and modules, and then you loaded the MINC-2500 dataset by using data loaders that you created for the training and test sets.\n",
    "\n",
    "Then, you defined the architecture of the CNN, including specifying the layers of the network and how they're connected. After that, you instantiated the CNN model, and defined the loss function and optimizer that you used to train the model. These steps form the foundation of building a CNN with PyTorch.\n",
    "\n",
    "--- \n",
    "## Next lab\n",
    "In the next lab, you will learn how to build a model by using a modern architecture, ConvNeXt, with PyTorch. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
